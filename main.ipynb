{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import choice\n",
    "from collections import deque\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on wikigraph.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported the reduced csv file containing for each single edge in the graph the starting node (Named Source) and the final node (Named Target). To obtain a correct display we used a separator with respect to the tab and subsequently we renamed the two columns 0,1 as Source and Target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph = functions.read_graph_csv(\"wikigraph_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>1185516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>1059989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>1062426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>1161925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>541222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source   Target\n",
       "0      95  1185516\n",
       "1     108  1059989\n",
       "2     108  1062426\n",
       "3     108  1161925\n",
       "4     134   541222"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on page names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have uploaded the Text file containing the names of each single page. Once loaded, to obtain a correct view, we wanted to split the single column containing both the name of the page and the node associated with the page into two separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Node</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chiasmal syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kleroterion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pinakion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LyndonHochschildSerre spectral sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zariski's main theorem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Pages\n",
       "Node                                         \n",
       "0                           Chiasmal syndrome\n",
       "1                                 Kleroterion\n",
       "2                                    Pinakion\n",
       "3     LyndonHochschildSerre spectral sequence\n",
       "4                      Zariski's main theorem"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = functions.read_page_names(\"Names.txt\")\n",
    "data_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on topcast categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we uploaded the text file containing the list of pages associated with this category for each single category. Also in this case for a correct visualization we have carried out various operations. Once you have read the text file with separator and division into columns. We then worked on the two columns, on the Category column we deleted the initial part of the string for each row while for the PageList column we split the pages and created a list. We have also only considered categories with a number of articles between 5000 and 30000 as required by the Homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = functions.read_top_categories('Categories.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>PageList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English_footballers</td>\n",
       "      <td>[22860, 28411, 28961, 28979, 29264, 29573, 295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The_Football_League_players</td>\n",
       "      <td>[14003, 23536, 27109, 27348, 27459, 27989, 280...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Association_football_forwards</td>\n",
       "      <td>[26876, 26877, 26879, 26887, 26892, 26904, 269...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Association_football_midfielders</td>\n",
       "      <td>[14003, 15291, 23536, 26880, 26882, 26885, 268...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Association_football_defenders</td>\n",
       "      <td>[15217, 22860, 26873, 26878, 26881, 26898, 269...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Category  \\\n",
       "0               English_footballers   \n",
       "1       The_Football_League_players   \n",
       "2     Association_football_forwards   \n",
       "3  Association_football_midfielders   \n",
       "4    Association_football_defenders   \n",
       "\n",
       "                                            PageList  \n",
       "0  [22860, 28411, 28961, 28979, 29264, 29573, 295...  \n",
       "1  [14003, 23536, 27109, 27348, 27459, 27989, 280...  \n",
       "2  [26876, 26877, 26879, 26887, 26892, 26904, 269...  \n",
       "3  [14003, 15291, 23536, 26880, 26882, 26885, 268...  \n",
       "4  [15217, 22860, 26873, 26878, 26881, 26898, 269...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to create a new data frame containing the category of belonging for each article. Subsequently we created a dictionary containing the individual articles as keys and the categories of belonging as values for each key. We did it all because one article might belong to a single category or multiple ones. In the case of multiple appearance, we have to break the ties uniformly at random. We have in fact modified the dictionary created by randomly choosing the category it belongs to for each article. Subsequently we obtained the reverse dictionary by choosing the various categories as keys and the list of pages associated with them as values for each key and finally we obtained a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article = pd.concat([pd.DataFrame(data = {'Articles': data_cat.loc[i].PageList, \n",
    "                                             'Category': data_cat.loc[i].Category}) for i in data_cat.index], \n",
    "                       ignore_index=True) #Create a new datagrame where for each article we report the specific category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Articles</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22860</td>\n",
       "      <td>English_footballers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28411</td>\n",
       "      <td>English_footballers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28961</td>\n",
       "      <td>English_footballers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28979</td>\n",
       "      <td>English_footballers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29264</td>\n",
       "      <td>English_footballers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Articles             Category\n",
       "0    22860  English_footballers\n",
       "1    28411  English_footballers\n",
       "2    28961  English_footballers\n",
       "3    28979  English_footballers\n",
       "4    29264  English_footballers"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_article.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 198958/198958 [00:07<00:00, 25070.58it/s]\n"
     ]
    }
   ],
   "source": [
    "random_dict = functions.random_dictionary(df_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = functions.reversed_dictionary(random_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>PageList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English_footballers</td>\n",
       "      <td>[22860, 28961, 28979, 29573, 30896, 31902, 340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Association_football_defenders</td>\n",
       "      <td>[28411, 29264, 48583, 72617, 72628, 72747, 727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Year_of_death_missing</td>\n",
       "      <td>[29582, 72528, 72587, 72769, 72826, 72961, 729...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Association_football_midfielders</td>\n",
       "      <td>[30900, 72488, 73054, 73120, 73132, 73195, 732...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The_Football_League_players</td>\n",
       "      <td>[33973, 48582, 48714, 48922, 72521, 72532, 725...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Category  \\\n",
       "0               English_footballers   \n",
       "1    Association_football_defenders   \n",
       "2             Year_of_death_missing   \n",
       "3  Association_football_midfielders   \n",
       "4       The_Football_League_players   \n",
       "\n",
       "                                            PageList  \n",
       "0  [22860, 28961, 28979, 29573, 30896, 31902, 340...  \n",
       "1  [28411, 29264, 48583, 72617, 72628, 72747, 727...  \n",
       "2  [29582, 72528, 72587, 72769, 72826, 72961, 729...  \n",
       "3  [30900, 72488, 73054, 73120, 73132, 73195, 732...  \n",
       "4  [33973, 48582, 48714, 48922, 72521, 72532, 725...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RQ1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Graph\n",
    "As a first step we can check if the graph is directed or not.\n",
    "### Is the graph directed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We create a new dataframe where the columns of 'graph' are inverted in order to create the list of edge for both of the dataframe and check in they are equal. In case of a positive answer we can say that the graph is not directed because for each edge from node _a_ to node _b_ there is an edge from node _b_ to node _a_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph is directed\n"
     ]
    }
   ],
   "source": [
    "functions.is_directed(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is directed since there exists an edge from a certain node _a_ to a node _b_ but not from _b_ to _a_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After figuring out if the graph was direct or not, we have created an empty Direct graph through the networkx package using as nodes all the elements belonging to the Source and Target columns in the reduced downloaded dataframe. We then created arcs from the ith node of the Source column to the ith node of the Target column, all weighted with a value equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = functions.create_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many articles are we considering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained the total number of nodes in the graph by reporting all the elements of the two columns in the downloaded dataset in the form of a set in order to eliminate any duplication. Once this was done we created a new set given by the union of the previous sets and we calculated its length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = functions.number_articles(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98343"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many hyperlinks between pages exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of hyperlinks belonging to the graph is equal to the number of edges present. This value corresponds to the length of the reduced datasaet downloaded as we can consider it as the Edge List of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = functions.number_hyperlinks(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483094"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the average number of links in an arbitrary page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained the average of links for each node in the graph by calculating the overall sum of the degrees of each single node in the graph and dividing this sum by the number of nodes in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.824674862471147"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions.average_links(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the degree obtained is a direct degree then we can define its density given by the ratio between the number of arcs in the degree and the binomial coefficient of the number of nodes out of 2. The binomial coefficient is multiplied by two being a direct graph and consequently being fundamental the direction of the arch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\displaystyle D={\\frac {|E|}{2{\\binom {|V|}{2}}}}={\\frac {|E|}{|V|(|V|-1)}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9951571365597335e-05"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions.graph_density(nodes,edges) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our graph is a sparse graph whose density D is in the lower range of the density's codomain, or $0 \\leq D < \\frac {1} {2}$. To confirm this we can compare the number of maximum arcs for the graph created with the previously calculated edges value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of max edges is 9671247306 while the value of edges is equals 483094\n"
     ]
    }
   ],
   "source": [
    "functions.comparison_edges(nodes,edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Degree's nodes distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we reported through a plot nodes'degree distribution by defining its degree for each single node within the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "functions.plot_degree_dist(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RQ2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take in input the starting node and the number of clicks $d$, then starting from initial node we reach all the node at level $k$  with $k\\leq d$ considering the starting node as level 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example we can compute all the pages reachable starting from node 95 with 3 clicks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = list(functions.clicks(G, 95, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Node</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1595904</th>\n",
       "      <td>Reba McEntire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182721</th>\n",
       "      <td>Ma (album)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061891</th>\n",
       "      <td>Jodie Foster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067523</th>\n",
       "      <td>Valentine (film)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060361</th>\n",
       "      <td>Rose McGowan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Pages\n",
       "Node                     \n",
       "1595904     Reba McEntire\n",
       "1182721        Ma (album)\n",
       "1061891      Jodie Foster\n",
       "1067523  Valentine (film)\n",
       "1060361      Rose McGowan"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name.iloc[cl].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RQ3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ask for a category as input, then we search for this category in the dataframe containing all the categories and if the category falls, we insert all the pages associated with that category in the set \"nodes\". Then we return either the set nodes or if the category is not present in the dataframe the string \"No Category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>PageList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English_footballers</td>\n",
       "      <td>[22860, 28961, 28979, 29573, 29582, 30896, 319...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Year_of_birth_missing</td>\n",
       "      <td>[28411, 72580, 72829, 73047, 75306, 75577, 757...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Association_football_defenders</td>\n",
       "      <td>[29264, 48583, 72617, 72628, 72797, 72798, 728...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Association_football_midfielders</td>\n",
       "      <td>[30900, 72488, 72631, 73066, 73109, 73213, 732...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The_Football_League_players</td>\n",
       "      <td>[33973, 48582, 48730, 72483, 72521, 72528, 725...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Category  \\\n",
       "0               English_footballers   \n",
       "1             Year_of_birth_missing   \n",
       "2    Association_football_defenders   \n",
       "3  Association_football_midfielders   \n",
       "4       The_Football_League_players   \n",
       "\n",
       "                                            PageList  \n",
       "0  [22860, 28961, 28979, 29573, 29582, 30896, 319...  \n",
       "1  [28411, 72580, 72829, 73047, 75306, 75577, 757...  \n",
       "2  [29264, 48583, 72617, 72628, 72797, 72798, 728...  \n",
       "3  [30900, 72488, 72631, 73066, 73109, 73213, 732...  \n",
       "4  [33973, 48582, 48730, 72483, 72521, 72528, 725...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Category?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ask to put in input a category to define the list of pages that we want to reach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Category: Year_of_death_missing\n"
     ]
    }
   ],
   "source": [
    "nodes = functions.category(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72605, 72664, 72826, 72839, 72852]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the list of nodes obtained for the specific category, let's search for the most central node. We use degree-centrality as a measure of centrality. We get the degree-centrality with respect to the entire graph and then we return a dictionary containing as keys the nodes of the specific category and for each node its own centrality, finally we get the dictionary key with the maximum value. The key obtained represents centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = functions.degree_centrality(G,nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "871888"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Minimum Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the minimum distance necessary so that starting from the most central node we could reach all the pages of the specific Category, we tried to search for the ShortestPath following the BFS (Breadth-first-Search) algorithm. Starting from the initial (most central) node, we searched for all its neighbors we visited. Each visited node becomes the new node to visit so we increase the distance from the initial node by increasing the variable (start_distance +1). From the current node we search for new neighbors and we repeat the procedure until for the current node we are on there are no neighbors to that point we stop the search. We first check if the graph is connected. If this is not the case, we report the error otherwise we try to understand if all the nodes have been visited. If so we report the minimum distance otherwise we report the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial number Click obtained before the node on which one has arrived has no more neighbors is: 27\n",
      "Not Possible because Graph is not Connected\n"
     ]
    }
   ],
   "source": [
    " functions.minimum_distance(G,v,nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RQ4]\n",
    "### Step 1 : costructing the subgraph of C1 and C2\n",
    "To answer question 4 first of all we need to build the subgraph induced by the categories selected, the new graph contains the node of C1 and C2 and all the edges among the nodes of these two categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the first Category: Association_football_forwards\n",
      "Enter the second Category: Association_football_midfielders\n"
     ]
    }
   ],
   "source": [
    "C1 = input(\"Enter the first Category: \")\n",
    "C2 = input(\"Enter the second Category: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_sub = functions.sub_graph(G, C1, C2, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 5283\\nNumber of edges: 7789\\nAverage in degree:   1.4744\\nAverage out degree:   1.4744'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let v and u two arbitrary pages in the subgraph. What is the minimum set of hyperlinks one can remove to disconnect u and v?\n",
    "This is a <b> min cut </b> problem : we want to find the minimum number of edges to remove in order to disconect two given nodes in the graph. <br>\n",
    "We can solve this problem using two main results:\n",
    "- Max-flow min-cut theorem\n",
    "- Ford_Fulkerson algorithm <br>\n",
    "The theorem asserts that <i>the maximum amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut</i> and the algorithm can find the maximum flow so the minimum cut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ford_Fulkerson algorithm\n",
    "This algorithm needs the support of a BFS algorithm that returns the path from the node u to node v, if it exists. The idea behind the algorithm is as follows: as long as there is a path from the source (start node) to the sink (end node), with available capacity on all edges in the path, we send flow along one of the paths. Then we find another path, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to give an efficient implementation of the algorithm we map the nodes of G_sub into [0,...,len(G_sub.nodes)] and then, we build the adjacency matrix associated at this graph. The function _nx.adjacency_matrix()_ provided by networkx library returns a sparse matrix that we can convert in a numpy matrix using _.toarray()_ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping G_sub into [0,...,len(G_sub.nodes)]\n",
    "mapping = {old_label:new_label for new_label, old_label in enumerate(G_sub.nodes())}\n",
    "H_sub = nx.relabel_nodes(G_sub, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sparse adjacency matrix\n",
    "Adj_Mat_sparse = nx.adjacency_matrix(H_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy adjacency matrix\n",
    "Adj_Mat = Adj_Mat_sparse.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nodes u and v of H_sub picked at random\n",
    "u = choice(list(H_sub.nodes))\n",
    "v = choice(list(H_sub.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_cut = functions.ford_fulkerson(Adj_Mat, u, v)\n",
    "min_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RQ5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_categories.txt',encoding='utf-8') as json_file:\n",
    "    categories = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.outgoing = defaultdict(list)\n",
    "        self.incoming = defaultdict(list)\n",
    "        self.edges = []\n",
    "    def insert_edge(self, u, v):\n",
    "        self.outgoing[u].append(v)\n",
    "        self.incoming[v].append(u)\n",
    "        self.edges.append((u,v))\n",
    "    def vertices(self):\n",
    "        return list(set(self.outgoing.keys()) | set(self.incoming.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperlinks_Id</th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>796</td>\n",
       "      <td>95</td>\n",
       "      <td>1185516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>909</td>\n",
       "      <td>108</td>\n",
       "      <td>1059989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>910</td>\n",
       "      <td>108</td>\n",
       "      <td>1062426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>911</td>\n",
       "      <td>108</td>\n",
       "      <td>1161925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1141</td>\n",
       "      <td>134</td>\n",
       "      <td>541222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hyperlinks_Id  Source   Target\n",
       "0            796      95  1185516\n",
       "1            909     108  1059989\n",
       "2            910     108  1062426\n",
       "3            911     108  1161925\n",
       "4           1141     134   541222"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'wikigraph_reduced.csv'\n",
    "dataset = pd.read_csv(path)\n",
    "dataset = dataset.rename(columns={\"Unnamed: 0\": \"Hyperlinks_Id\", \"0\": \"Source\", \"1\": \"Target\"})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()\n",
    "_ = dataset.apply(lambda row: g.insert_edge(row['Source'], row['Target']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortpath(graph, source, articles):\n",
    "\n",
    "    v = [source]\n",
    "    lvl = [source]\n",
    "    \n",
    "    distances = dict.fromkeys(articles, -1)\n",
    "    count = 1\n",
    "    while True:\n",
    "        new_lvl = []\n",
    "        for article in lvl:\n",
    "            for adj in graph.incident_edges(article):\n",
    "                if adj not in v:\n",
    "                    new_lvl.append(adj)\n",
    "                    v.append(adj)\n",
    "                    if adj in articles:\n",
    "                        distances[adj] = count\n",
    "        if len(new_lvl) == 0:\n",
    "            break\n",
    "        lvl = new_lvl\n",
    "        count +=1\n",
    "    \n",
    "    if (np.array(list(distances.values())) == -1).all():\n",
    "        return -1\n",
    "    else:\n",
    "        shortest_distance = min([distance for article, distance in distances.items() if distance != -1])\n",
    "        \n",
    "    return shortest_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_distance(graph, categories, input_category):\n",
    "\n",
    "    cate_distances = {}\n",
    "    \n",
    "    for category, articles in categories.items():\n",
    "        shortest_path = {}\n",
    "        articles = [int(article) for article in articles if article in graph.vertices()]\n",
    "        if category != input_category:\n",
    "            for source in categories[input_category]:\n",
    "                if source in graph.vertices():\n",
    "                    shortest_distance = shortpath(graph, int(source), articles)\n",
    "                    \n",
    "                    if shortest_distance == -1: \n",
    "                         continue\n",
    "                    else:\n",
    "                        shortest_path[source] = shortest_distance\n",
    "            \n",
    "            if len(shortest_path) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                median = np.median([shortest for source, shortest in shortest_path.items()])\n",
    "                cate_distances[category] = median\n",
    "    if len(cate_distances) == 0:\n",
    "        return 'Input Category have no connection with the other categories'\n",
    "    else:\n",
    "        return dict(sorted(cate_distances.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-251bc586e971>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mc0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Category:Association_football_forwards'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcategory_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-96-c164bd857729>\u001b[0m in \u001b[0;36mcategory_distance\u001b[1;34m(graph, categories, input_category)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcategory\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minput_category\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msource\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_category\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                     \u001b[0mshortest_distance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshortestpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marticles\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# return shortest distance from source to articles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c0 = 'Category:Association_football_forwards'\n",
    "category_distance(g, categories, c0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RQ6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PageRank(G, d = 0.85, max_iter = 100):\n",
    "    probs_node = { x: 1 / len(G) for x in G.nodes }                                                                   \n",
    "    out_degrees = { x: G.out_degree(x) if G.out_degree(x) != 0 else len(G) for x in G.nodes }                         \n",
    "    \n",
    "    new_probs_node = probs_node.copy()                                                                                 \n",
    "                                                                                                                       \n",
    "    for _ in tqdm(range(max_iter)):                                                                                    \n",
    "        for p_x in new_probs_node:                                                                                                         \n",
    "            ratios_sum = sum([ probs_node[neigh] / out_degrees[neigh] for neigh in nx.neighbors(G, p_x) ])             \n",
    "            new_probs_node[p_x] = ( ( 1 - d ) / len(G) ) + ( d * ratios_sum )                                          \n",
    "        \n",
    "            probs_node = new_probs_node.copy()\n",
    "    \n",
    "    return new_probs_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful create a dict\n",
    "refer_dt = data_cat[data_cat['Category'].isin(list(new_dat[\"Category\"]))]\n",
    "lst_category = list(refer_dt['Category'])\n",
    "\n",
    "lst_pages = [ set(map(int, lst_pg )) for lst_pg in list(refer_dt[\"PageList\"]) ]\n",
    "my_dict = { cat: lst_pages[i] for i, cat in enumerate(lst_category) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new graph of categories and inserts the node as one category\n",
    "new_G = nx.DiGraph(directed=True)\n",
    "for cat in lst_category:\n",
    "    new_G.add_node(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 158.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# add edges\n",
    "for x in tqdm(my_dict):\n",
    "    for y in my_dict:\n",
    "        if (x != y and len(my_dict[x].intersection(my_dict[y])) > 0):\n",
    "            new_G.add_edge(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 7713.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9190476190476178"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_PageRank = PageRank(new_G)\n",
    "sum(total_PageRank.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
